{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redes adversárias generativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "São duas redes colocadas uma contra a outra:\n",
    "Uma rede discrinadora D e uma rede geradora G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função custo a ser otimizada depende da qualidade de G e da classificação de D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As duas redes estão em conflito direto!\n",
    "\n",
    "A otimização segue a lógica de teoria dos jogos e procura o ponto \"min max\" do sistema.\n",
    "Alternamos entre k passos de otimização de D e n passos de otimização de G.\n",
    "Podemos ter k=n=1, k>n, K>>n,...\n",
    "\n",
    "Obs: Ainda está tendo muito estudo sobre a melhor maneira de otimizar GANs.\n",
    "\n",
    "Conflito: G quer \"enganar\" D, e D quer identificar a trapaça de G. Mas queremos otimizar as duas ao mesmo tempo! Então vamos alternando entre as duas otimizações."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sugestão inicial de treinamento:\n",
    "Treinar K passos de uma rede, enquanto congela os pesos da outra.\n",
    "Assim que terminar esses k passos, treinar n passos da outra rede, congelando os pesos da primeira.\n",
    "\n",
    "Foram observados alguns problemas computacionais no treinamento de redes com esse custo, principalmente quando G aprende que existe um tipo especifico de falsificação que D tem mais dificuldade de discernir, e ai decide fazer toas as suas falsificações parecidissimas entre si.\n",
    "\n",
    "Para isso foi proposta a função custo Wasserstein em 2017 que é a que se usa no TF-GAN(implementação de GAN para o TensorFlow feita por pesquisadores do google)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função custo Wasserstein\n",
    "\n",
    "Essa função custo é um pouco mais simples, e as redes treinadas com ela têm menos chance de ficarem \"presas\" na otimização.\n",
    "\n",
    "Diferença da GAN usual para a WGAN(Wasserstein GAN):\n",
    "\n",
    "A GAN usual, na sua parte discriminativa(D), outputta um número entre 0 e 1 que corresponde á probabilidade de um certo dado ser real.   -> GAN tem um \"discriminador\"\n",
    "\n",
    "A WGAN outputta um número real (não precisa estar entre 0 e 1), tentando fazer com que o output seja maior para dados reais e menor para dados falsificados.   -> WGAN tem um \"crítico\"\n",
    "\n",
    "Perda do crítico na WGAN: Diferença entre valor que o crítico dá para um dado real (x) e um dado falso(G(z))\n",
    "        D(x) - D(G(z))    O crítico quer que isso seja grande\n",
    "        \n",
    "Perda do gerador na WGAN: Valor que o crítico dá para um dado falso(G(z))\n",
    "        D(G(z))           O gerador quer que isso seja grande"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

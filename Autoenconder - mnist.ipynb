{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "#Aqui a gente n√£o vai usar o y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.choice(range(len(train_X)))\n",
    "plt.imshow(train_X[i], cmap = 'gray')\n",
    "print(train_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape(60000,28,28,1)\n",
    "test_X = test_X.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 11, 11, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 8, 16)          8208      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 1, 1, 16)          4112      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1, 1, 1)           17        \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 14, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 31,441\n",
      "Trainable params: 31,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(28,28,1)))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(16, kernel_size=4, activation='relu'))\n",
    "model.add(MaxPooling2D(padding='same'))\n",
    "#model.add(UpSampling2D())\n",
    "model.add(Conv2D(16, kernel_size=4, activation='relu'))\n",
    "model.add(MaxPooling2D(padding='same'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "model.add(UpSampling2D(size=(14,14)))\n",
    "#model.add(Conv2D(16, kernel_size=3, activation='relu'))\n",
    "model.add(UpSampling2D(size=(2,2)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 7217.3320 - val_loss: 7343.5415\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 7217.3271 - val_loss: 7343.5415\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 123s 123ms/step - loss: 7217.3311 - val_loss: 7343.5415\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 7217.3335 - val_loss: 7343.5415\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 7217.3281 - val_loss: 7343.5415\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 7217.3296 - val_loss: 7343.5415\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 7217.3340 - val_loss: 7343.5415\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 7217.3296 - val_loss: 7343.5415\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 7217.3320 - val_loss: 7343.5415\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 7217.3291 - val_loss: 7343.5415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6b580b37f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'rmsprop', loss = 'mse')\n",
    "\n",
    "model.fit(x = train_X, y = train_X, batch_size = 60, epochs = 10, validation_data = (test_X, test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "750/750 [==============================] - 119s 159ms/step - loss: 7217.3281 - val_loss: 7343.5430\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 136s 181ms/step - loss: 7217.3301 - val_loss: 7343.5430\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 129s 172ms/step - loss: 7217.3291 - val_loss: 7343.5430\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 106s 141ms/step - loss: 7217.3311 - val_loss: 7343.5430\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 106s 141ms/step - loss: 7217.3306 - val_loss: 7343.5430\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 135s 180ms/step - loss: 7217.3320 - val_loss: 7343.5430\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 103s 138ms/step - loss: 7217.3306 - val_loss: 7343.5430\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 108s 144ms/step - loss: 7217.3286 - val_loss: 7343.5430\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 111s 148ms/step - loss: 7217.3281 - val_loss: 7343.5430\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 107s 143ms/step - loss: 7217.3340 - val_loss: 7343.5430\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 125s 166ms/step - loss: 7217.3286 - val_loss: 7343.5430\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 104s 139ms/step - loss: 7217.3311 - val_loss: 7343.5430\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 126s 168ms/step - loss: 7217.3271 - val_loss: 7343.5430\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 128s 171ms/step - loss: 7217.3291 - val_loss: 7343.5430\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 109s 145ms/step - loss: 7217.3262 - val_loss: 7343.5430\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 105s 140ms/step - loss: 7217.3315 - val_loss: 7343.5430\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 105s 140ms/step - loss: 7217.3286 - val_loss: 7343.5430\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 106s 141ms/step - loss: 7217.3296 - val_loss: 7343.5430\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 119s 159ms/step - loss: 7217.3335 - val_loss: 7343.5430\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 106s 141ms/step - loss: 7217.3291 - val_loss: 7343.5430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6b38137100>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = train_X, y = train_X, batch_size = 80, epochs = 20, validation_data = (test_X, test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x = train_X, y = train_X, batch_size = 15, epochs = 15, verbose = 2, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X_train = model.predict(train_X)\n",
    "pred_X_test = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.choice(range(len(train_X)))\n",
    "plt.imshow(pred_X_train[i].reshape(28,28), cmap = 'gray')\n",
    "print(train_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.choice(range(len(test_X)))\n",
    "plt.imshow(pred_X_train[i].reshape(28,28), cmap = 'gray')\n",
    "print(train_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
